{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPMzTezB1q8coqSBOg+QaVO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zz-z5AftnjGr","executionInfo":{"status":"ok","timestamp":1676240016764,"user_tz":-360,"elapsed":32962,"user":{"displayName":"Md. Sabbir Hossain","userId":"07040019536784709022"}},"outputId":"a6f92a78-d1be-4d9a-96ca-7eb7ad1e8f89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 Cost: 1.4309908214318403\n","Epoch: 100 Cost: 0.6584688377652311\n","Epoch: 200 Cost: 0.627556327731398\n","Epoch: 300 Cost: 0.6138572286357231\n","Epoch: 400 Cost: 0.6054340442042825\n","Epoch: 500 Cost: 0.5996185472231214\n","Epoch: 600 Cost: 0.5953604414080269\n","Epoch: 700 Cost: 0.5921292783718302\n","Epoch: 800 Cost: 0.5896175105608108\n","Epoch: 900 Cost: 0.587630245194625\n","Epoch: 1000 Cost: 0.5860362549347732\n","Epoch: 1100 Cost: 0.5847433370369834\n","Epoch: 1200 Cost: 0.5836846827898975\n","Epoch: 1300 Cost: 0.5828107523660405\n","Epoch: 1400 Cost: 0.5820841412540299\n","Epoch: 1500 Cost: 0.5814761883782126\n","Epoch: 1600 Cost: 0.5809646567809891\n","Epoch: 1700 Cost: 0.5805321050637443\n","Epoch: 1800 Cost: 0.5801647196833398\n","Epoch: 1900 Cost: 0.5798514633934341\n","Epoch: 2000 Cost: 0.5795834454154238\n","Epoch: 2100 Cost: 0.5793534499367358\n","Epoch: 2200 Cost: 0.5791555793598552\n","Epoch: 2300 Cost: 0.578984981779764\n","Epoch: 2400 Cost: 0.5788376409731415\n","Epoch: 2500 Cost: 0.5787102132414113\n","Epoch: 2600 Cost: 0.5785998996875492\n","Epoch: 2700 Cost: 0.5785043455123215\n","Epoch: 2800 Cost: 0.5784215600731453\n","Epoch: 2900 Cost: 0.578349853013826\n","Epoch: 3000 Cost: 0.5782877829194618\n","Epoch: 3100 Cost: 0.5782341157972017\n","Epoch: 3200 Cost: 0.5781877913136526\n","Epoch: 3300 Cost: 0.5781478951922271\n","Epoch: 3400 Cost: 0.5781136365305959\n","Epoch: 3500 Cost: 0.5780843290696595\n","Epoch: 3600 Cost: 0.5780593756529692\n","Epoch: 3700 Cost: 0.5780382552752594\n","Epoch: 3800 Cost: 0.5780205122423638\n","Epoch: 3900 Cost: 0.5780057470610591\n","Epoch: 4000 Cost: 0.5779936087526972\n","Epoch: 4100 Cost: 0.5779837883437596\n","Epoch: 4200 Cost: 0.5779760133333403\n","Epoch: 4300 Cost: 0.5779700429747918\n","Epoch: 4400 Cost: 0.5779656642385198\n","Epoch: 4500 Cost: 0.577962688346746\n","Epoch: 4600 Cost: 0.5779609477902763\n","Epoch: 4700 Cost: 0.5779602937528473\n","Epoch: 4800 Cost: 0.5779605938812615\n","Epoch: 4900 Cost: 0.5779617303498044\n","Epoch: 5000 Cost: 0.5779635981758896\n","Epoch: 5100 Cost: 0.5779661037507823\n","Epoch: 5200 Cost: 0.5779691635550002\n","Epoch: 5300 Cost: 0.5779727030326849\n","Epoch: 5400 Cost: 0.5779766556032089\n","Epoch: 5500 Cost: 0.5779809617915181\n","Epoch: 5600 Cost: 0.5779855684614792\n","Epoch: 5700 Cost: 0.5779904281387761\n","Epoch: 5800 Cost: 0.577995498411841\n","Epoch: 5900 Cost: 0.5780007414009295\n","Epoch: 6000 Cost: 0.5780061232868289\n","Epoch: 6100 Cost: 0.5780116138918544\n","Epoch: 6200 Cost: 0.5780171863067813\n","Epoch: 6300 Cost: 0.5780228165582111\n","Epoch: 6400 Cost: 0.5780284833115885\n","Epoch: 6500 Cost: 0.5780341676057102\n","Epoch: 6600 Cost: 0.5780398526150934\n","Epoch: 6700 Cost: 0.5780455234370339\n","Epoch: 6800 Cost: 0.5780511669005813\n","Epoch: 6900 Cost: 0.5780567713949897\n","Epoch: 7000 Cost: 0.5780623267155057\n","Epoch: 7100 Cost: 0.5780678239246173\n","Epoch: 7200 Cost: 0.5780732552270944\n","Epoch: 7300 Cost: 0.5780786138573566\n","Epoch: 7400 Cost: 0.5780838939778812\n","Epoch: 7500 Cost: 0.5780890905874863\n","Epoch: 7600 Cost: 0.5780941994384847\n","Epoch: 7700 Cost: 0.5780992169617969\n","Epoch: 7800 Cost: 0.5781041401992192\n","Epoch: 7900 Cost: 0.5781089667421279\n","Epoch: 8000 Cost: 0.5781136946759855\n","Epoch: 8100 Cost: 0.578118322530072\n","Epoch: 8200 Cost: 0.5781228492319316\n","Epoch: 8300 Cost: 0.5781272740660829\n","Epoch: 8400 Cost: 0.5781315966365757\n","Epoch: 8500 Cost: 0.5781358168330292\n","Epoch: 8600 Cost: 0.5781399347998276\n","Epoch: 8700 Cost: 0.5781439509081648\n","Epoch: 8800 Cost: 0.5781478657306833\n","Epoch: 8900 Cost: 0.5781516800184564\n","Epoch: 9000 Cost: 0.5781553946801038\n","Epoch: 9100 Cost: 0.5781590107628423\n","Epoch: 9200 Cost: 0.578162529435294\n","Epoch: 9300 Cost: 0.5781659519718931\n","Epoch: 9400 Cost: 0.5781692797387468\n","Epoch: 9500 Cost: 0.5781725141808197\n","Epoch: 9600 Cost: 0.5781756568103207\n","Epoch: 9700 Cost: 0.5781787091961874\n","Epoch: 9800 Cost: 0.5781816729545708\n","Epoch: 9900 Cost: 0.5781845497402263\n","Accuracy: 0.9333333333333333\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","\n","# Load the Iris dataset\n","iris = load_iris()\n","X = iris[\"data\"]\n","y = iris[\"target\"]\n","\n","# One-hot encode the target variable\n","y = np.eye(3)[y]\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize the parameters\n","num_features = X_train.shape[1]\n","weights = np.zeros((num_features, 3))\n","bias = np.zeros(3)\n","\n","# Define the sigmoid function\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","# Define the cost function\n","def cost(X, y, weights, bias):\n","    m = X.shape[0]\n","    y_pred = sigmoid(X @ weights + bias)\n","    cost = -1 / m * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n","    return cost\n","\n","# Define the gradient function\n","def gradient(X, y, weights, bias):\n","    m = X.shape[0]\n","    y_pred = sigmoid(X @ weights + bias)\n","    d_weights = 1 / m * X.T @ (y_pred - y)\n","    d_bias = 1 / m * np.sum(y_pred - y)\n","    return d_weights, d_bias\n","\n","# Define the learning rate and number of epochs\n","learning_rate = 0.01\n","num_epochs = 10000\n","\n","# Train the model using SGD\n","for epoch in range(num_epochs):\n","    for i, x in enumerate(X_train):\n","        d_weights, d_bias = gradient(x.reshape(1, -1), y_train[i].reshape(1, -1), weights, bias)\n","        weights -= learning_rate * d_weights\n","        bias -= learning_rate * d_bias\n","        \n","    if epoch % 100 == 0:\n","        print(\"Epoch:\", epoch, \"Cost:\", cost(X_train, y_train, weights, bias))\n","\n","# Evaluate the model on the test set\n","y_pred = sigmoid(X_test @ weights + bias)\n","y_pred = np.argmax(y_pred, axis=1)\n","y_test = np.argmax(y_test, axis=1)\n","accuracy = np.mean(y_pred == y_test)\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"tPVYOiFurprK"},"execution_count":null,"outputs":[]}]}